---
defaults:
  - override hydra/sweeper: optuna
hydra:  
  # consider_prior: true
  # prior_weight: 1.0  
  sweeper:
    sampler:
      _target_: optuna.samplers.TPESampler
    direction: maximize
    study_name: crisis2023timetraveler
    storage: null
    n_trials: 2000
    n_jobs: 1
    params: 
      max_action_num: choice(30, 50, 80, 100, 200)
      ent_dim: choice(80, 100, 150)
      mu: choice(0.1, 0.3, 0.5, 0.7, 0.9)
      path_length: choice(2,3,4)
      lr: choice(0.001, 0.00001)
data_path: crisis2023 #help='Path to data.
cuda: True # help='whether to use GPU or not.') 
do_train: True #help='whether to train.') 
do_test: True # help='whether to test.') 
save_path: logs3 #', type=str, help='log and model save path.')
load_model_path: None # logs3 #None #logs3 #help='trained model checkpoint path.')
batch_size: 512 #, type=int, help='training batch size.')
max_epochs: 11 #400 #, type=int, help='max training epochs.') 
num_workers: 8 #, type=int, help='workers number used for dataloader.')
valid_epoch: 10 #30 #30 #, type=int, help='validation frequency.') 
lr: 0.00001 #, type=float, help='learning rate.')
save_epoch: 10 #, type=int, help='model saving frequency.') 
clip_gradient: 10.0 #, type=float, help='for gradient crop.')
test_batch_size: 1 #, type=int,                         help='test batch size, it needs to be set to 1 when using IM module.')
beam_size: 100 #, type=int, help='the beam number of the beam search.')
test_inductive: False #', action='store_true', help='whether to verify inductive inference performance.')
IM: False #', action='store_true', help='whether to use IM module.')
mu: 0.1 #, type=float, help='the hyperparameter of IM module.')
ent_dim: 80 #, type=int, help='Embedding dimension of the entities') #julia set to 80 in run.py due to A.3
rel_dim: 100 #, type=int, help='Embedding dimension of the relations') 
state_dim: 100 #, type=int, help='dimension of the LSTM hidden state')
hidden_dim: 100 #, type=int, help='dimension of the MLP hidden layer')
time_dim: 20 #, type=int, help='Embedding dimension of the timestamps')
entities_embeds_method: dynamic #', type=str,
                       # help='representation method of the entities, dynamic or static')
state_actions_path: state_actions_space.pkl #', type=str,
                      # help='the file stores preprocessed candidate action array.')
path_length: 3 #, type=int, help='the agent search path length.')
max_action_num: 80 #, type=int, help='the max candidate actions number.') # Julia: this is N - A.3: 50 for ICEWS14 and ICEWS18, 60 for WIKI, and 30 for YAGO
Lambda: 0.0 #, type=float, help='update rate of baseline.')
Gamma: 0.95 #, type=float, help='discount factor of Bellman Eq.')
Ita: 0.01 #, type=float, help='regular proportionality constant.')
Zita: 0.9 #, type=float, help='attenuation factor of entropy regular term.')
reward_shaping: True # ', action='store_true', help='whether to use reward shaping.') #julia in run.py: set to True
time_span: 1 #, type=int, help='24 for ICEWS, 1 for WIKI and YAGO')
alphas_pkl: dirchlet_alphas.pkl #', type=str,                         help='the file storing the alpha parameters of the Dirichlet distribution.')
k: 300 #, type=int, help='statistics recent K historical snapshots.')
setting: time #', choices=['time', 'static', 'raw' ]) #added julia for logging
singleormultistep: singlestep #', choices=['singlestep', 'multistep' ]) #added julia for logging
